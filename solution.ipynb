{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4acc5fe1",
   "metadata": {},
   "source": [
    "### solution_v1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5a02",
   "metadata": {},
   "source": [
    "### 1. 环境初始化与数据加载\n",
    "首先，我们导入numpy,pandas计算库，并读取原始数据集，并展示数据集基础信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = 'source_data'\n",
    "train_data = pd.read_csv(data_path +'/train.csv')\n",
    "test_data = pd.read_csv(data_path +'/test.csv')\n",
    "# 查看训练数据的信息\n",
    "train_data.info()\n",
    "#train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb90664",
   "metadata": {},
   "source": [
    "可以看到train_data共 891 个样本，其中所包含属性如下\n",
    "- PassengerId => 乘客ID\n",
    "- Survived => 乘客是否存活\n",
    "- Pclass => 乘客等级(1/2/3等舱位)\n",
    "- Name => 乘客姓名\n",
    "- Sex => 性别\n",
    "- Age => 年龄:缺失了 177 个值 ,   缺失率19.8%\n",
    "- SibSp => 堂兄弟/妹个数\n",
    "- Parch => 父母与小孩个数\n",
    "- Ticket => 船票信息\n",
    "- Fare => 票价\n",
    "- Cabin => 客舱号码：缺失了  687 个值， 缺失率77.1%\n",
    "- Embarked => 登船港口：缺失了 2 个值 缺失率0.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261765e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c8b27",
   "metadata": {},
   "source": [
    "可以了解到test_data一共 418 个样本，其中缺失属性如下\n",
    "- Age => 年龄:缺失了 86 个值 ,   缺失率20.5%\n",
    "- Fare => 票价:缺失了 1 个值 ，  缺失率0.2%\n",
    "- Cabin => 客舱号码：缺失了  327 个值， 缺失率78.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9329eb34",
   "metadata": {},
   "source": [
    "### 2.探索性数据分析 ：\n",
    "在建模之前，先分析可能影响的因素。通过可视化手段分析:\n",
    "性别和年龄是否影响逃生机会（Sex, Age）\n",
    "仓位登记和票价是否影响逃生机会？（Pclass, Fare）\n",
    "登船地点是否存在隐含的生存规律？（Embarked）\n",
    "下面的图表将分别从分类特征和数值分布两个维度揭示这些规律。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ffd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked 缺失值为2个，直接用众数填充\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5896e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare 缺失值为1个，用 Train 的中位数去填，假设他买了张普通票\n",
    "# 确保计算人均票价正常注意使用train_data的中位数\n",
    "test_data['Fare'] = test_data['Fare'].fillna(train_data['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe00799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex  分析男性和女性中各自的比率\n",
    "survival_by_sex = train_data.groupby('Sex')['Survived']\n",
    "print(survival_by_sex.mean)\n",
    "\n",
    "# 绘图\n",
    "fig, axes = plt.subplots(figsize=(4, 3)) \n",
    "survival_by_sex.sum().plot(kind='bar', color=['skyblue'])\n",
    "axes.set_title('Survival Count by Sex', fontsize=14)\n",
    "axes.set_ylabel('Survival Count')\n",
    "axes.set_xlabel('Sex')\n",
    "axes.tick_params(axis='x', rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass  分析不同舱位的生存率\n",
    "survival_by_pclass = train_data.groupby('Pclass')['Survived'].mean()\n",
    "print(survival_by_pclass)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(train_data, x='Pclass', hue='Survived')\n",
    "plt.title('Survival Count by Pclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked  分析不同登船港口的生存率\n",
    "survival_by_embarked = train_data.groupby('Embarked')['Survived'].mean()\n",
    "print(survival_by_embarked)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(train_data, x='Embarked', hue='Survived')\n",
    "plt.title('Survival Count by Embarked')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e17cd5",
   "metadata": {},
   "source": [
    "### 3. 特征工程：高级特征构造 \n",
    "- Title ：从 Name 提取 Mr, Mrs, Miss, Master。这极大地帮助树模型划分社会地位。\n",
    "- FarePerPerson 从ticker中提取团体票和个人票，更真实的反应每个人的票价\n",
    "- FamilySize ：SibSp + Parch + 1。将原始数据中的 SibSp 和 Parch 合并为 FamilySize。树模型可以很容易找到 FamilySize > 4 存活率骤降的分割点。\n",
    "进一步降噪，鲁棒性，非线性表达。将familysize 分为3组 独自1人/ 2-4人/5人及以上\n",
    "- IsAlone ：基于 FamilySize 创建的二分类特征 (0/1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4318c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取名字中的称谓\n",
    "#[A-Za-z]表示匹配任意字母，+表示匹配前面的字符一次或多次，\\.表示匹配点号本身 \\转移符\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_data['Title'] = test_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "# 查看不同称谓的分布情况\n",
    "# print(train_data['Title'].value_counts())\n",
    "# 将一些罕见的称谓归类为'Other'，注意要记录test的特殊数据\n",
    "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', \n",
    "               'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "#replace函数用于替换指定的值 ,第一个参数是要被替换的值，第二个参数是替换成的值\n",
    "train_data['Title'] = train_data['Title'].replace(rare_titles, 'Other')\n",
    "test_data['Title'] = test_data['Title'].replace(rare_titles, 'Other')\n",
    "# 将常见的称谓进行统一\n",
    "train_data['Title'] = train_data['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "test_data['Title'] = test_data['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "\n",
    "# 检查是否有未映射的 Title\n",
    "if train_data['Title'].isnull().any():\n",
    "    print(\"警告：有 Title 没被映射成功！\")\n",
    "    print(train_data[train_data['Title'].isnull()])\n",
    "\n",
    "if test_data['Title'].isnull().any():\n",
    "    print(\"警告：有 Title 没被映射成功！\")\n",
    "    print(test_data[test_data['Title'].isnull()])\n",
    "\n",
    "# 查看处理后的称谓分布情况\n",
    "# print(train_data['Title'].value_counts())\n",
    "# 分析不同称谓的生存率\n",
    "survival_by_title = train_data.groupby('Title')['Survived'].mean()  \n",
    "print(\"不同称谓的生存率：\")\n",
    "print(survival_by_title)\n",
    "# 查看现在的 Title 各个值的数量\n",
    "print(train_data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于ticket号，计算人均票价\n",
    "all_data = pd.concat([train_data, test_data], sort=False)\n",
    "ticket_counts = all_data.groupby('Ticket').size()\n",
    "print(ticket_counts)\n",
    "# 映射原数据\n",
    "train_data['TicketCount'] = train_data['Ticket'].map(ticket_counts)\n",
    "test_data['TicketCount'] = test_data['Ticket'].map(ticket_counts)   \n",
    "# 计算人均票价\n",
    "train_data['FarePerPerson'] = train_data['Fare'] / train_data['TicketCount']\n",
    "test_data['FarePerPerson'] = test_data['Fare'] / test_data['TicketCount']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60557d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造家庭大小为新特征\n",
    "train_data[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\n",
    "test_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1\n",
    "\n",
    "# 根据家庭规模创建家庭组别特征 分箱\n",
    "train_data['FamilyGroup'] = 0\n",
    "# 创建家庭规模类别特征   分别为 单身(0) 小家庭(1) 大家庭(2)\n",
    "train_data.loc[(train_data['FamilySize'] >= 2) & (train_data['FamilySize'] <= 4), 'FamilyGroup'] = 1\n",
    "train_data.loc[train_data['FamilySize'] >= 5, 'FamilyGroup'] = 2\n",
    "\n",
    "\n",
    "# test进行同样的处理\n",
    "test_data['FamilyGroup'] = 0\n",
    "test_data.loc[(test_data['FamilySize'] >= 2) & (test_data['FamilySize'] <= 4), 'FamilyGroup'] = 1\n",
    "test_data.loc[test_data['FamilySize'] >= 5, 'FamilyGroup'] = 2\n",
    "print(\"\\n分组后的生存率统计：\")\n",
    "print(train_data[['FamilyGroup', 'Survived']].groupby('FamilyGroup').mean())\n",
    "print(\"创建完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2efa88",
   "metadata": {},
   "source": [
    "### 4.高级数据清洗：基于随机森林的 MICE 填补\n",
    "数据属性中较少的缺失值采用简单的均值/中位数/众数填充\n",
    "数据属性中缺失值较多的采用 Iterative Imputer技术。 简单来说，将“预测年龄”视为一个回归问题：利用 Pclass, Fare, FamilySize 等已知信息，通过随机森林回归模型来精准反推缺失的 Age。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "#缺失值填补用FamilySize 模型训练用FamilyGroup\n",
    "# 生存率呈现 \"中间高，两头低\" 的非线性关系，使用FamilyGroup分组后模型更容易学\n",
    "features_for_impute = ['Pclass', 'Sex', 'FamilySize', 'Fare', 'Age', 'Embarked', 'Title', 'FarePerPerson']\n",
    "df_train_impute = train_data[features_for_impute].copy()\n",
    "\n",
    "\n",
    "# 2.独热编码：把所有特征数字化\n",
    "# 'Sex' -> 0 / 1\n",
    "df_train_impute['Sex'] = df_train_impute['Sex'].map({'male': 0, 'female': 1})\n",
    "# 'Embarked' -> 0 / 1 / 2\n",
    "df_train_impute['Embarked'] = df_train_impute['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}) \n",
    "# 'Title' -> 0 / 1 / 2 / 3 / 4\n",
    "df_train_impute['Title'] = df_train_impute['Title'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4})\n",
    "\n",
    "\n",
    "# 3. 配置填充器：IterativeImputer\n",
    "# estimator: 采用“随机森林回归”来预测缺失值\n",
    "rf_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_jobs=-1,              # n_jobs=-1 使用所有可用的 CPU 核心来加速训练\n",
    "        random_state=42\n",
    "    ),\n",
    "    max_iter=10,                # max_iter: 迭代轮数10次\n",
    "    random_state=42             # 设置随机种子，使得每次运行结果相同\n",
    ")\n",
    "\n",
    "# 4. 训练阶段 (Fit) - 此时只看不做\n",
    "# 这一步，rf_imputer 只是在“观察”数据，寻找年龄和其他特征的规律\n",
    "print(\"正在学习训练集的规律...\")\n",
    "rf_imputer.fit(df_train_impute) \n",
    "\n",
    "# 5. 应用阶段 (Transform) - 此时只做不想\n",
    "# 这一步，用刚才学到的规律，把训练集自己的坑填上\n",
    "print(\"正在填充训练集...\")\n",
    "imputed_data = rf_imputer.transform(df_train_impute)\n",
    "\n",
    "\n",
    "\n",
    "# 6. 还原回 DataFrame\n",
    "df_filled = pd.DataFrame(imputed_data, columns=features_for_impute)\n",
    "\n",
    "# 把填好的 Age 塞回原始数据\n",
    "train_data['Age'] = df_filled['Age'].round(0)\n",
    "\n",
    "# 7. 修正非法值\n",
    "# 如果预测出负数，强制变为 1；如果太大，限制在 80\n",
    "train_data.loc[train_data['Age'] < 0, 'Age'] = 1\n",
    "train_data.loc[train_data['Age'] > 80, 'Age'] = 80\n",
    "\n",
    "print(\"基于随机森林的智能填充完成！\")\n",
    "print(train_data[['Age', 'Embarked']].isnull().sum()) # 检查缺失值数量\n",
    "print(\"Age 缺失值填充完毕!前10个结果预览:\")\n",
    "print(train_data['Age'].head(10))\n",
    "print(\"填补后的 Master 平均年龄:\", train_data[train_data['Title'] == 'Master']['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62c3b9",
   "metadata": {},
   "source": [
    "### 5.测试集填补 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae87567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修复 Test 集的 缺失值- \n",
    "# Age => 年龄:缺失了 86 个值 ,   缺失率20.5%\n",
    "# Fare => 票价:缺失了 1 个值 ，  缺失率0.2%\n",
    "\n",
    "\n",
    "# 2. 修复 Age (86 个缺失值)\n",
    "# 用训练好的 rf_imputer 去预测 Test 的年龄\n",
    "# 第一步：准备数据 (格式必须和训练 imputer 时一模一样)\n",
    "features_for_impute = ['Pclass', 'Sex', 'FamilySize', 'Fare', 'Age', 'Embarked','Title', 'FarePerPerson']\n",
    "df_test_impute = test_data[features_for_impute].copy()\n",
    "\n",
    "# 3.独热编码 - 特征数字化 (Sex/Embarked 转数字)\n",
    "df_test_impute['Sex'] = df_test_impute['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test_impute['Embarked'] = df_test_impute['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "df_test_impute['Title'] = df_test_impute['Title'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4})  \n",
    "\n",
    "# 4.应用 Train训练集 学到的规律 (Transform)，只需要 transform\n",
    "test_imputed_data = rf_imputer.transform(df_test_impute)\n",
    "\n",
    "# 5.把填好的 Age 填充 test_data\n",
    "df_test_filled = pd.DataFrame(test_imputed_data, columns=features_for_impute)\n",
    "test_data['Age'] = df_test_filled['Age'].round(0).astype(int)\n",
    "\n",
    "# 6.修正非法值\n",
    "test_data.loc[test_data['Age'] < 0, 'Age'] = 1\n",
    "test_data.loc[test_data['Age'] > 80, 'Age'] = 80\n",
    "\n",
    "\n",
    "print(\"现在剩余的 NaN 情况：\")\n",
    "print(test_data[['Age', 'Fare']].isnull().sum()) # 查看缺失值数量\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad6381",
   "metadata": {},
   "source": [
    "### 6.模型训练与提交\n",
    "我们使用 随机森林分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"FamilyGroup\", \"FarePerPerson\", 'Title']\n",
    "# 独热编码\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "# 自动补齐测试集中缺失的列（补为0），并确保顺序一致\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "print(f\"训练集形状: {X.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 网格搜索交叉验证调参\n",
    "\n",
    "# 定义“尝试”的参数范围 (Param Grid)\n",
    "# 模型训练与预测 \n",
    "'''\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 400, 700],        # 树越多越稳定\n",
    "    'max_depth': [4, 6, 8, 10],                 # 树越深学得越细，但也越容易过拟合\n",
    "    'min_samples_leaf': [2, 4, 6],              # 叶子节点最少样本数：太小会过拟合\n",
    "    'min_samples_split': [2, 4, 10],        # 分裂门槛：太小会过拟合\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "        n_jobs=-1,              # 使用所有可用的 CPU 核心来加速训练\n",
    "        random_state=42         # 设置随机种子，使得每次运行结果相同\n",
    ")\n",
    "\n",
    "# 4. 创建“搜索器” (GridSearchCV)\n",
    "# cv=5: 意思是做 5折交叉验证 (把数据切成5份，轮流验证，防止偶然性)\n",
    "# n_jobs=-1: 调用你电脑所有的 CPU 核心一起跑，加速\n",
    "# verbose=2: 打印进度条，数字1表示打印少量信息，数字越大信息越多\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           cv=5, verbose=2)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "print(f\" 最佳参数组合: {grid_search.best_params_}\")\n",
    "print(f\" 最佳验证集分数: {grid_search.best_score_:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "最佳参数组合: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "最佳验证集分数: 0.8451\n",
    "'''\n",
    "model = RandomForestClassifier(\n",
    "        n_estimators=400,        # 树越多越稳定\n",
    "        max_depth=10,                 # 树越深学得越细，但也越\n",
    "        min_samples_leaf=2,              # 叶子节点最少样本数：太小会过拟合\n",
    "        min_samples_split=2,        # 分裂门槛：太小会过\n",
    "        n_jobs=-1,              # 使用所有可用的 CPU 核心来加速训练\n",
    "        random_state=42         # 设置随机种子，使得每次运行结果相同\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5043d6",
   "metadata": {},
   "source": [
    "### 7.模型评估：交叉验证 (CV)\n",
    "采用交叉验证 (Cross Validation) 分析模型的表现。通过将训练数据切分为 5 份，轮流进行“模拟考试”，得到一个比单一分数更可信的平均分和标准差，从而判断模型的泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# cv=5 表示考 5 次，每次考题都不一样\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"每次考试的分数: {scores}\")\n",
    "print(f\"本地估算平均分: {scores.mean():.4f}\")\n",
    "print(f\"标准差 (越小越稳): {scores.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
